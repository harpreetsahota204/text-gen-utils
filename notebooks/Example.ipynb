{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oHgjuizF6RN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install transformers langchain accelerate wandb bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install -U flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFTqpy26KQxl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import wandb\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig, GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUZ5ivf2KEwt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/harpreetsahota204/text-gen-utils.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqLckotaLBsY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/text-gen-utils/text-gen-utils')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEluxAasK5me"
      },
      "outputs": [],
      "source": [
        "from text_gen_utils import gen_pipeline, run_single_param_experiment, run_experiments, instantiate_huggingface_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-nZ31S0t1jW"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ejn6wCMQVVC"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTRyU85Wjz3h"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx9J53FNKehS"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"Enter your WandB API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJua4-HN30yi"
      },
      "outputs": [],
      "source": [
        "red_teaming_prompts = load_dataset('harpreetsahota/elicit-offensive-language-prompts', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4MtX8VXiKli"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF8tviFBf2HJ"
      },
      "outputs": [],
      "source": [
        "gen_params = {\n",
        "    \"temperature\": [1e-3, .25, .50, .75, 1.0],\n",
        "    \"num_beams\": [1, 3, 5, 7],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjmQMuREO86t"
      },
      "outputs": [],
      "source": [
        "decilm = AutoModelForCausalLM.from_pretrained(\"Deci/DeciLM-7b-redteam4-lm_eval\",\n",
        "                                              device_map=\"auto\",\n",
        "                                              quantization_config=bnb_config,\n",
        "                                              trust_remote_code=True)\n",
        "\n",
        "mistral = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\",\n",
        "                                               device_map=\"auto\",\n",
        "                                               quantization_config=bnb_config,\n",
        "                                               trust_remote_code=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\",\n",
        "                                          padding_side=\"left\")\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "deci_generator = pipeline(\"text-generation\",\n",
        "                          model=decilm,\n",
        "                          tokenizer=tokenizer,\n",
        "                          device_map=\"auto\",\n",
        "                          do_sample=True,\n",
        "                          early_stopping=True,\n",
        "                          max_length=250\n",
        ")\n",
        "\n",
        "mistral_generator = pipeline(\"text-generation\",\n",
        "                          model=mistral,\n",
        "                          tokenizer=tokenizer,\n",
        "                          device_map=\"auto\",\n",
        "                          do_sample=True,\n",
        "                          early_stopping=True,\n",
        "                          max_length=250,\n",
        ")\n",
        "\n",
        "pipelines = {\n",
        "    'DeciLM': deci_generator,\n",
        "    'Mistral': mistral_generator\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cV08A1agO8rg"
      },
      "outputs": [],
      "source": [
        "results = run_experiments(pipelines,\n",
        "                          red_teaming_prompts,\n",
        "                          gen_params,\n",
        "                          gen_pipeline,\n",
        "                          'Prompt',\n",
        "                          'red-teaming-offensive-language',\n",
        "                          'harp-deci')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkyMlAK5bNVF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "generated_dataset = Dataset.from_dict(results_df)\n",
        "\n",
        "generated_dataset.push_to_hub('harpreetsahota/red-team-offensive-language-results', private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g83e_qf7bVv9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}